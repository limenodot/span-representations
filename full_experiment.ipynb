{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "data = pd.read_csv('train_top5.csv')['class'].values.reshape(-1, 1)\n",
    "onehot_encoder.fit(data)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, onehot_encoder, method='endpoint'):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.labels = onehot_encoder.transform(self.data['class'].values.reshape(-1, 1))\n",
    "        self.method = method\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        file_path = self.data.iloc[idx]['path']\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        raw_embedding = torch.load(file_path)\n",
    "        if self.method == 'endpoint':\n",
    "            embedding = torch.cat((raw_embedding[:, 0, :], raw_embedding[:, -1, :]), dim=1)\n",
    "        elif self.method == 'diff-sum':\n",
    "            embedding = torch.cat(\n",
    "                (\n",
    "                    raw_embedding[:, 0, :] + raw_embedding[:, -1, :],\n",
    "                    raw_embedding[:, 0, :] - raw_embedding[:, -1, :]\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        elif self.method == 'coherent':\n",
    "            embedding = torch.cat(\n",
    "                (\n",
    "                    raw_embedding[:, 0, :360],\n",
    "                    raw_embedding[:, -1, 360:720],\n",
    "                    torch.dot(\n",
    "                        raw_embedding[:, 0, :].squeeze()[720:],\n",
    "                        raw_embedding[:, -1, :].squeeze()[720:]\n",
    "                    ).unsqueeze(0).unsqueeze(0)\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        elif self.method == 'maxpool':\n",
    "            embedding = torch.max(raw_embedding, dim=1)[0]\n",
    "        elif self.method == 'avgpool':\n",
    "            embedding = torch.mean(raw_embedding, dim=1)\n",
    "\n",
    "        return embedding, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomDeepClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=1536, num_classes=20, hidden_dim=2048):\n",
    "        super(CustomDeepClassifier, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.BatchNorm1d(1))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.BatchNorm1d(1))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, num_classes))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = F.softmax(x, dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_validate_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.1, stepslr=10, gamma=0.9):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, stepslr, gamma=gamma)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), total=num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "        \n",
    "        train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if (epoch + 1) % stepslr == 0:\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs.float())\n",
    "                    loss = criterion(outputs.squeeze(), labels)\n",
    "                    running_val_loss += loss.item()\n",
    "\n",
    "                    predicted = torch.argmax(outputs.squeeze(1), 1)\n",
    "                    labels = torch.argmax(labels, 1)\n",
    "                    all_preds.extend(predicted.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            val_loss = running_val_loss / len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}] \"\n",
    "                f\"Train Loss: {train_loss:.4f} \"\n",
    "                f\"Val Loss: {val_loss:.4f} \"\n",
    "                f\"Precision: {precision:.4f} \"\n",
    "                f\"Recall: {recall:.4f} \"\n",
    "                f\"F1 Score: {f1:.4f}\\n\")\n",
    "            print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    return train_losses, val_losses, precision_scores, recall_scores, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/400 [23:32<3:33:28, 35.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/400] Train Loss: 1.7778 Val Loss: 1.7872 Precision: 0.3590 Recall: 0.2719 F1 Score: 0.2661\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.16      0.21       183\n",
      "           1       0.12      0.18      0.15       119\n",
      "           2       0.62      0.10      0.17       548\n",
      "           3       0.33      0.22      0.26       285\n",
      "           4       0.74      0.71      0.73      1801\n",
      "           5       0.05      0.26      0.08       150\n",
      "\n",
      "    accuracy                           0.48      3086\n",
      "   macro avg       0.36      0.27      0.27      3086\n",
      "weighted avg       0.60      0.48      0.50      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 80/400 [46:22<3:09:35, 35.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/400] Train Loss: 1.7832 Val Loss: 1.7910 Precision: 0.3254 Recall: 0.1931 F1 Score: 0.0753\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.97      0.12       183\n",
      "           1       0.20      0.03      0.04       119\n",
      "           2       0.39      0.02      0.03       548\n",
      "           3       0.38      0.06      0.11       285\n",
      "           4       0.88      0.07      0.14      1801\n",
      "           5       0.03      0.01      0.01       150\n",
      "\n",
      "    accuracy                           0.11      3086\n",
      "   macro avg       0.33      0.19      0.08      3086\n",
      "weighted avg       0.63      0.11      0.10      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 120/400 [1:09:00<2:41:37, 34.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/400] Train Loss: 1.7819 Val Loss: 1.7895 Precision: 0.3515 Recall: 0.2083 F1 Score: 0.1098\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.84      0.12       183\n",
      "           1       0.17      0.07      0.10       119\n",
      "           2       0.60      0.06      0.11       548\n",
      "           3       0.29      0.04      0.07       285\n",
      "           4       0.93      0.10      0.18      1801\n",
      "           5       0.06      0.14      0.08       150\n",
      "\n",
      "    accuracy                           0.13      3086\n",
      "   macro avg       0.35      0.21      0.11      3086\n",
      "weighted avg       0.69      0.13      0.14      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 160/400 [1:30:47<2:12:49, 33.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/400] Train Loss: 1.7817 Val Loss: 1.7884 Precision: 0.2891 Recall: 0.1972 F1 Score: 0.1210\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.69      0.11       183\n",
      "           1       0.07      0.05      0.06       119\n",
      "           2       0.50      0.05      0.09       548\n",
      "           3       0.21      0.16      0.18       285\n",
      "           4       0.86      0.13      0.22      1801\n",
      "           5       0.04      0.11      0.06       150\n",
      "\n",
      "    accuracy                           0.15      3086\n",
      "   macro avg       0.29      0.20      0.12      3086\n",
      "weighted avg       0.62      0.15      0.18      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [1:51:33<1:47:36, 32.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/400] Train Loss: 1.7748 Val Loss: 1.7847 Precision: 0.3988 Recall: 0.3854 F1 Score: 0.3642\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.52      0.41       183\n",
      "           1       0.18      0.18      0.18       119\n",
      "           2       0.45      0.48      0.46       548\n",
      "           3       0.49      0.10      0.17       285\n",
      "           4       0.82      0.80      0.81      1801\n",
      "           5       0.12      0.23      0.16       150\n",
      "\n",
      "    accuracy                           0.61      3086\n",
      "   macro avg       0.40      0.39      0.36      3086\n",
      "weighted avg       0.64      0.61      0.61      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 240/400 [2:12:12<1:25:56, 32.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [240/400] Train Loss: 1.7740 Val Loss: 1.7836 Precision: 0.4035 Recall: 0.4230 F1 Score: 0.4015\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.43      0.41       183\n",
      "           1       0.24      0.17      0.20       119\n",
      "           2       0.47      0.53      0.50       548\n",
      "           3       0.29      0.48      0.36       285\n",
      "           4       0.92      0.70      0.80      1801\n",
      "           5       0.10      0.22      0.14       150\n",
      "\n",
      "    accuracy                           0.59      3086\n",
      "   macro avg       0.40      0.42      0.40      3086\n",
      "weighted avg       0.68      0.59      0.63      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 280/400 [2:32:48<1:04:30, 32.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [280/400] Train Loss: 1.7742 Val Loss: 1.7848 Precision: 0.3862 Recall: 0.3662 F1 Score: 0.3062\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.78      0.27       183\n",
      "           1       0.26      0.08      0.13       119\n",
      "           2       0.43      0.50      0.46       548\n",
      "           3       0.44      0.05      0.09       285\n",
      "           4       0.89      0.71      0.79      1801\n",
      "           5       0.14      0.07      0.10       150\n",
      "\n",
      "    accuracy                           0.56      3086\n",
      "   macro avg       0.39      0.37      0.31      3086\n",
      "weighted avg       0.66      0.56      0.58      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 320/400 [2:53:22<42:46, 32.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [320/400] Train Loss: 1.7736 Val Loss: 1.7841 Precision: 0.3904 Recall: 0.4492 F1 Score: 0.3938\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.67      0.44       183\n",
      "           1       0.11      0.31      0.16       119\n",
      "           2       0.54      0.39      0.45       548\n",
      "           3       0.28      0.46      0.34       285\n",
      "           4       0.93      0.70      0.80      1801\n",
      "           5       0.16      0.17      0.17       150\n",
      "\n",
      "    accuracy                           0.58      3086\n",
      "   macro avg       0.39      0.45      0.39      3086\n",
      "weighted avg       0.70      0.58      0.62      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 360/400 [3:13:54<21:26, 32.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [360/400] Train Loss: 1.7736 Val Loss: 1.7834 Precision: 0.4127 Recall: 0.4303 F1 Score: 0.4056\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40       183\n",
      "           1       0.15      0.20      0.17       119\n",
      "           2       0.45      0.58      0.51       548\n",
      "           3       0.30      0.54      0.38       285\n",
      "           4       0.94      0.69      0.80      1801\n",
      "           5       0.14      0.23      0.18       150\n",
      "\n",
      "    accuracy                           0.60      3086\n",
      "   macro avg       0.41      0.43      0.41      3086\n",
      "weighted avg       0.70      0.60      0.63      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [3:34:25<00:00, 32.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/400] Train Loss: 1.7735 Val Loss: 1.7847 Precision: 0.4039 Recall: 0.4516 F1 Score: 0.4088\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.62      0.41       183\n",
      "           1       0.18      0.23      0.20       119\n",
      "           2       0.44      0.57      0.50       548\n",
      "           3       0.43      0.32      0.37       285\n",
      "           4       0.92      0.69      0.79      1801\n",
      "           5       0.14      0.29      0.19       150\n",
      "\n",
      "    accuracy                           0.59      3086\n",
      "   macro avg       0.40      0.45      0.41      3086\n",
      "weighted avg       0.69      0.59      0.62      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_csv_path = 'train_top5.csv'\n",
    "test_csv_path = 'dev_top5.csv'\n",
    "\n",
    "method = 'endpoint'\n",
    "\n",
    "train_dataset = CustomDataset(train_csv_path, onehot_encoder, method=method)\n",
    "test_dataset = CustomDataset(test_csv_path, onehot_encoder, method=method)\n",
    "\n",
    "train_batch_size = 256\n",
    "test_batch_size = 256\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "model = CustomDeepClassifier(input_dim=train_dataset[0][0].shape[1], num_classes=6)\n",
    "tl, vl, p, r, f1 = train_validate_model(model,\n",
    "                                        train_data_loader,\n",
    "                                        test_data_loader,\n",
    "                                        num_epochs=400,\n",
    "                                        learning_rate=3e-2,\n",
    "                                        stepslr=40,\n",
    "                                        gamma=0.9)\n",
    "\n",
    "torch.save(model.state_dict(), f'best_model_{method}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/400 [18:55<2:58:15, 29.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/400] Train Loss: 1.7846 Val Loss: 1.7930 Precision: 0.2694 Recall: 0.1778 F1 Score: 0.0664\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.84      0.11       183\n",
      "           1       0.00      0.00      0.00       119\n",
      "           2       0.38      0.01      0.01       548\n",
      "           3       0.20      0.02      0.03       285\n",
      "           4       0.93      0.09      0.17      1801\n",
      "           5       0.05      0.11      0.07       150\n",
      "\n",
      "    accuracy                           0.11      3086\n",
      "   macro avg       0.27      0.18      0.07      3086\n",
      "weighted avg       0.63      0.11      0.12      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 80/400 [37:51<2:38:21, 29.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/400] Train Loss: 1.7829 Val Loss: 1.7885 Precision: 0.2758 Recall: 0.2327 F1 Score: 0.2222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.05      0.08       183\n",
      "           1       0.04      0.05      0.05       119\n",
      "           2       0.27      0.21      0.24       548\n",
      "           3       0.34      0.14      0.20       285\n",
      "           4       0.77      0.59      0.67      1801\n",
      "           5       0.05      0.34      0.09       150\n",
      "\n",
      "    accuracy                           0.42      3086\n",
      "   macro avg       0.28      0.23      0.22      3086\n",
      "weighted avg       0.54      0.42      0.46      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 120/400 [56:45<2:18:21, 29.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/400] Train Loss: 1.7833 Val Loss: 1.7929 Precision: 0.3338 Recall: 0.2159 F1 Score: 0.1260\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.90      0.12       183\n",
      "           1       0.14      0.05      0.07       119\n",
      "           2       0.48      0.09      0.16       548\n",
      "           3       0.35      0.04      0.07       285\n",
      "           4       0.87      0.15      0.25      1801\n",
      "           5       0.09      0.07      0.08       150\n",
      "\n",
      "    accuracy                           0.17      3086\n",
      "   macro avg       0.33      0.22      0.13      3086\n",
      "weighted avg       0.64      0.17      0.20      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 160/400 [1:15:38<1:58:33, 29.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/400] Train Loss: 1.7840 Val Loss: 1.7898 Precision: 0.3300 Recall: 0.2148 F1 Score: 0.1233\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.90      0.12       183\n",
      "           1       0.12      0.03      0.04       119\n",
      "           2       0.52      0.04      0.07       548\n",
      "           3       0.33      0.07      0.12       285\n",
      "           4       0.82      0.18      0.29      1801\n",
      "           5       0.11      0.08      0.09       150\n",
      "\n",
      "    accuracy                           0.17      3086\n",
      "   macro avg       0.33      0.21      0.12      3086\n",
      "weighted avg       0.62      0.17      0.21      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [1:34:27<1:38:15, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/400] Train Loss: 1.7744 Val Loss: 1.7853 Precision: 0.3840 Recall: 0.3831 F1 Score: 0.3755\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.40      0.43       183\n",
      "           1       0.19      0.12      0.15       119\n",
      "           2       0.42      0.58      0.49       548\n",
      "           3       0.28      0.40      0.33       285\n",
      "           4       0.85      0.78      0.81      1801\n",
      "           5       0.09      0.03      0.05       150\n",
      "\n",
      "    accuracy                           0.62      3086\n",
      "   macro avg       0.38      0.38      0.38      3086\n",
      "weighted avg       0.63      0.62      0.62      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 240/400 [1:53:12<1:18:36, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [240/400] Train Loss: 1.7735 Val Loss: 1.7837 Precision: 0.3905 Recall: 0.4473 F1 Score: 0.3911\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.62      0.38       183\n",
      "           1       0.20      0.19      0.20       119\n",
      "           2       0.51      0.45      0.48       548\n",
      "           3       0.31      0.50      0.39       285\n",
      "           4       0.93      0.63      0.75      1801\n",
      "           5       0.11      0.30      0.16       150\n",
      "\n",
      "    accuracy                           0.55      3086\n",
      "   macro avg       0.39      0.45      0.39      3086\n",
      "weighted avg       0.69      0.55      0.60      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 280/400 [2:11:57<58:52, 29.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [280/400] Train Loss: 1.7745 Val Loss: 1.7867 Precision: 0.4281 Recall: 0.3462 F1 Score: 0.3520\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.22      0.31       183\n",
      "           1       0.23      0.15      0.18       119\n",
      "           2       0.44      0.60      0.51       548\n",
      "           3       0.47      0.12      0.19       285\n",
      "           4       0.81      0.81      0.81      1801\n",
      "           5       0.08      0.18      0.11       150\n",
      "\n",
      "    accuracy                           0.62      3086\n",
      "   macro avg       0.43      0.35      0.35      3086\n",
      "weighted avg       0.64      0.62      0.61      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 320/400 [2:30:43<39:21, 29.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [320/400] Train Loss: 1.7732 Val Loss: 1.7829 Precision: 0.4438 Recall: 0.4200 F1 Score: 0.3766\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.46      0.47       183\n",
      "           1       0.12      0.21      0.16       119\n",
      "           2       0.58      0.33      0.42       548\n",
      "           3       0.43      0.38      0.41       285\n",
      "           4       0.97      0.51      0.67      1801\n",
      "           5       0.08      0.63      0.14       150\n",
      "\n",
      "    accuracy                           0.46      3086\n",
      "   macro avg       0.44      0.42      0.38      3086\n",
      "weighted avg       0.75      0.46      0.54      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 360/400 [2:50:30<21:27, 32.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [360/400] Train Loss: 1.7736 Val Loss: 1.7836 Precision: 0.4116 Recall: 0.4417 F1 Score: 0.3941\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.66      0.39       183\n",
      "           1       0.21      0.19      0.20       119\n",
      "           2       0.53      0.45      0.49       548\n",
      "           3       0.44      0.36      0.40       285\n",
      "           4       0.93      0.63      0.75      1801\n",
      "           5       0.09      0.35      0.14       150\n",
      "\n",
      "    accuracy                           0.55      3086\n",
      "   macro avg       0.41      0.44      0.39      3086\n",
      "weighted avg       0.71      0.55      0.60      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [3:11:04<00:00, 28.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/400] Train Loss: 1.7743 Val Loss: 1.7837 Precision: 0.3790 Recall: 0.4093 F1 Score: 0.3335\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.67      0.36       183\n",
      "           1       0.16      0.09      0.12       119\n",
      "           2       0.61      0.15      0.24       548\n",
      "           3       0.27      0.66      0.38       285\n",
      "           4       0.90      0.68      0.77      1801\n",
      "           5       0.10      0.21      0.13       150\n",
      "\n",
      "    accuracy                           0.54      3086\n",
      "   macro avg       0.38      0.41      0.33      3086\n",
      "weighted avg       0.68      0.54      0.56      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_csv_path = 'train_top5.csv'\n",
    "test_csv_path = 'dev_top5.csv'\n",
    "\n",
    "method = 'diff-sum'\n",
    "\n",
    "train_dataset = CustomDataset(train_csv_path, onehot_encoder, method=method)\n",
    "test_dataset = CustomDataset(test_csv_path, onehot_encoder, method=method)\n",
    "\n",
    "train_batch_size = 256\n",
    "test_batch_size = 256\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "model = CustomDeepClassifier(input_dim=train_dataset[0][0].shape[1], num_classes=6)\n",
    "tl, vl, p, r, f1 = train_validate_model(model,\n",
    "                                        train_data_loader,\n",
    "                                        test_data_loader,\n",
    "                                        num_epochs=400,\n",
    "                                        learning_rate=3e-2,\n",
    "                                        stepslr=40,\n",
    "                                        gamma=0.9)\n",
    "\n",
    "torch.save(model.state_dict(), f'best_model_{method}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/400 [20:22<3:11:10, 31.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/400] Train Loss: 1.7749 Val Loss: 1.7855 Precision: 0.3940 Recall: 0.3284 F1 Score: 0.3317\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.17      0.24       183\n",
      "           1       0.23      0.08      0.12       119\n",
      "           2       0.39      0.64      0.48       548\n",
      "           3       0.44      0.15      0.22       285\n",
      "           4       0.81      0.81      0.81      1801\n",
      "           5       0.12      0.12      0.12       150\n",
      "\n",
      "    accuracy                           0.62      3086\n",
      "   macro avg       0.39      0.33      0.33      3086\n",
      "weighted avg       0.62      0.62      0.60      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 80/400 [40:44<2:49:41, 31.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/400] Train Loss: 1.7741 Val Loss: 1.7853 Precision: 0.3873 Recall: 0.4231 F1 Score: 0.3978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.43      0.39       183\n",
      "           1       0.15      0.21      0.17       119\n",
      "           2       0.47      0.55      0.50       548\n",
      "           3       0.30      0.48      0.37       285\n",
      "           4       0.89      0.73      0.80      1801\n",
      "           5       0.17      0.14      0.15       150\n",
      "\n",
      "    accuracy                           0.61      3086\n",
      "   macro avg       0.39      0.42      0.40      3086\n",
      "weighted avg       0.67      0.61      0.63      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 120/400 [1:01:04<2:28:15, 31.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/400] Train Loss: 1.7737 Val Loss: 1.7842 Precision: 0.3807 Recall: 0.4155 F1 Score: 0.3848\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.48      0.43       183\n",
      "           1       0.14      0.13      0.13       119\n",
      "           2       0.46      0.52      0.49       548\n",
      "           3       0.27      0.44      0.34       285\n",
      "           4       0.91      0.66      0.77      1801\n",
      "           5       0.11      0.26      0.15       150\n",
      "\n",
      "    accuracy                           0.57      3086\n",
      "   macro avg       0.38      0.42      0.38      3086\n",
      "weighted avg       0.67      0.57      0.60      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 160/400 [1:21:23<2:07:15, 31.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/400] Train Loss: 1.7742 Val Loss: 1.7845 Precision: 0.4447 Recall: 0.3748 F1 Score: 0.3407\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.34      0.40       183\n",
      "           1       0.20      0.09      0.13       119\n",
      "           2       0.49      0.39      0.43       548\n",
      "           3       0.46      0.14      0.22       285\n",
      "           4       0.94      0.57      0.71      1801\n",
      "           5       0.08      0.71      0.15       150\n",
      "\n",
      "    accuracy                           0.48      3086\n",
      "   macro avg       0.44      0.37      0.34      3086\n",
      "weighted avg       0.72      0.48      0.55      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [1:41:43<1:45:44, 31.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/400] Train Loss: 1.7739 Val Loss: 1.7845 Precision: 0.4297 Recall: 0.3746 F1 Score: 0.3458\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.36      0.41       183\n",
      "           1       0.21      0.08      0.12       119\n",
      "           2       0.57      0.31      0.40       548\n",
      "           3       0.31      0.31      0.31       285\n",
      "           4       0.94      0.56      0.70      1801\n",
      "           5       0.08      0.63      0.13       150\n",
      "\n",
      "    accuracy                           0.47      3086\n",
      "   macro avg       0.43      0.37      0.35      3086\n",
      "weighted avg       0.72      0.47      0.55      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 240/400 [2:02:02<1:24:37, 31.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [240/400] Train Loss: 1.7734 Val Loss: 1.7838 Precision: 0.4200 Recall: 0.3842 F1 Score: 0.3424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.38      0.36       183\n",
      "           1       0.19      0.12      0.15       119\n",
      "           2       0.61      0.30      0.40       548\n",
      "           3       0.33      0.31      0.32       285\n",
      "           4       0.96      0.54      0.69      1801\n",
      "           5       0.08      0.67      0.14       150\n",
      "\n",
      "    accuracy                           0.45      3086\n",
      "   macro avg       0.42      0.38      0.34      3086\n",
      "weighted avg       0.73      0.45      0.54      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 280/400 [2:22:11<1:00:47, 30.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [280/400] Train Loss: 1.7738 Val Loss: 1.7843 Precision: 0.4168 Recall: 0.4211 F1 Score: 0.3792\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.42      0.41       183\n",
      "           1       0.17      0.31      0.22       119\n",
      "           2       0.60      0.34      0.43       548\n",
      "           3       0.30      0.37      0.33       285\n",
      "           4       0.94      0.60      0.74      1801\n",
      "           5       0.08      0.49      0.14       150\n",
      "\n",
      "    accuracy                           0.51      3086\n",
      "   macro avg       0.42      0.42      0.38      3086\n",
      "weighted avg       0.72      0.51      0.58      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 320/400 [2:40:44<37:52, 28.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [320/400] Train Loss: 1.7735 Val Loss: 1.7840 Precision: 0.4070 Recall: 0.4066 F1 Score: 0.3739\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.31      0.34       183\n",
      "           1       0.21      0.18      0.20       119\n",
      "           2       0.52      0.36      0.43       548\n",
      "           3       0.31      0.39      0.34       285\n",
      "           4       0.93      0.65      0.77      1801\n",
      "           5       0.10      0.54      0.17       150\n",
      "\n",
      "    accuracy                           0.53      3086\n",
      "   macro avg       0.41      0.41      0.37      3086\n",
      "weighted avg       0.70      0.53      0.59      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 360/400 [2:58:45<18:45, 28.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [360/400] Train Loss: 1.7742 Val Loss: 1.7858 Precision: 0.4143 Recall: 0.3680 F1 Score: 0.2992\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.66      0.32       183\n",
      "           1       0.26      0.11      0.15       119\n",
      "           2       0.62      0.10      0.17       548\n",
      "           3       0.42      0.16      0.23       285\n",
      "           4       0.89      0.69      0.78      1801\n",
      "           5       0.09      0.49      0.15       150\n",
      "\n",
      "    accuracy                           0.50      3086\n",
      "   macro avg       0.41      0.37      0.30      3086\n",
      "weighted avg       0.69      0.50      0.54      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [3:16:35<00:00, 29.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/400] Train Loss: 1.7743 Val Loss: 1.7841 Precision: 0.4697 Recall: 0.3383 F1 Score: 0.2986\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.09      0.16       183\n",
      "           1       0.18      0.11      0.14       119\n",
      "           2       0.55      0.28      0.37       548\n",
      "           3       0.47      0.22      0.30       285\n",
      "           4       0.96      0.53      0.68      1801\n",
      "           5       0.08      0.79      0.14       150\n",
      "\n",
      "    accuracy                           0.43      3086\n",
      "   macro avg       0.47      0.34      0.30      3086\n",
      "weighted avg       0.74      0.43      0.51      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_csv_path = 'train_top5.csv'\n",
    "test_csv_path = 'dev_top5.csv'\n",
    "\n",
    "method = 'coherent'\n",
    "\n",
    "train_dataset = CustomDataset(train_csv_path, onehot_encoder, method=method)\n",
    "test_dataset = CustomDataset(test_csv_path, onehot_encoder, method=method)\n",
    "\n",
    "train_batch_size = 256\n",
    "test_batch_size = 256\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "model = CustomDeepClassifier(input_dim=train_dataset[0][0].shape[1], num_classes=6)\n",
    "tl, vl, p, r, f1 = train_validate_model(model,\n",
    "                                        train_data_loader,\n",
    "                                        test_data_loader,\n",
    "                                        num_epochs=400,\n",
    "                                        learning_rate=3e-2,\n",
    "                                        stepslr=40,\n",
    "                                        gamma=0.9)\n",
    "\n",
    "torch.save(model.state_dict(), f'best_model_{method}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/400 [24:02<3:46:52, 37.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/400] Train Loss: 1.7766 Val Loss: 1.7873 Precision: 0.2940 Recall: 0.2802 F1 Score: 0.2734\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.15      0.17       183\n",
      "           1       0.10      0.12      0.11       119\n",
      "           2       0.48      0.20      0.28       548\n",
      "           3       0.27      0.41      0.33       285\n",
      "           4       0.68      0.80      0.74      1801\n",
      "           5       0.02      0.01      0.01       150\n",
      "\n",
      "    accuracy                           0.55      3086\n",
      "   macro avg       0.29      0.28      0.27      3086\n",
      "weighted avg       0.52      0.55      0.52      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 80/400 [48:19<3:21:44, 37.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/400] Train Loss: 1.7769 Val Loss: 1.7883 Precision: 0.3872 Recall: 0.2659 F1 Score: 0.2692\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.17      0.21       183\n",
      "           1       0.16      0.10      0.12       119\n",
      "           2       0.76      0.06      0.12       548\n",
      "           3       0.39      0.30      0.34       285\n",
      "           4       0.63      0.89      0.74      1801\n",
      "           5       0.10      0.07      0.08       150\n",
      "\n",
      "    accuracy                           0.58      3086\n",
      "   macro avg       0.39      0.27      0.27      3086\n",
      "weighted avg       0.57      0.58      0.51      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 120/400 [1:12:31<2:57:43, 38.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/400] Train Loss: 1.7823 Val Loss: 1.7885 Precision: 0.3840 Recall: 0.1823 F1 Score: 0.1147\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.56      0.09       183\n",
      "           1       0.15      0.07      0.09       119\n",
      "           2       0.95      0.03      0.07       548\n",
      "           3       0.29      0.12      0.17       285\n",
      "           4       0.82      0.11      0.19      1801\n",
      "           5       0.05      0.20      0.07       150\n",
      "\n",
      "    accuracy                           0.13      3086\n",
      "   macro avg       0.38      0.18      0.11      3086\n",
      "weighted avg       0.68      0.13      0.15      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 160/400 [1:36:51<2:36:23, 39.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/400] Train Loss: 1.7756 Val Loss: 1.7865 Precision: 0.3229 Recall: 0.2920 F1 Score: 0.2866\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.30      0.27       183\n",
      "           1       0.14      0.20      0.17       119\n",
      "           2       0.43      0.14      0.21       548\n",
      "           3       0.33      0.28      0.30       285\n",
      "           4       0.64      0.80      0.71      1801\n",
      "           5       0.14      0.03      0.05       150\n",
      "\n",
      "    accuracy                           0.54      3086\n",
      "   macro avg       0.32      0.29      0.29      3086\n",
      "weighted avg       0.51      0.54      0.51      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [2:01:20<2:07:22, 38.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/400] Train Loss: 1.7747 Val Loss: 1.7870 Precision: 0.3804 Recall: 0.3144 F1 Score: 0.2795\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.15      0.19       183\n",
      "           1       0.11      0.15      0.13       119\n",
      "           2       0.75      0.10      0.18       548\n",
      "           3       0.22      0.67      0.34       285\n",
      "           4       0.72      0.73      0.72      1801\n",
      "           5       0.21      0.09      0.12       150\n",
      "\n",
      "    accuracy                           0.52      3086\n",
      "   macro avg       0.38      0.31      0.28      3086\n",
      "weighted avg       0.60      0.52      0.51      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 240/400 [2:25:31<1:40:51, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [240/400] Train Loss: 1.7743 Val Loss: 1.7872 Precision: 0.3388 Recall: 0.3566 F1 Score: 0.3356\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.38      0.31       183\n",
      "           1       0.15      0.19      0.17       119\n",
      "           2       0.41      0.36      0.38       548\n",
      "           3       0.31      0.46      0.37       285\n",
      "           4       0.73      0.70      0.72      1801\n",
      "           5       0.17      0.04      0.06       150\n",
      "\n",
      "    accuracy                           0.55      3086\n",
      "   macro avg       0.34      0.36      0.34      3086\n",
      "weighted avg       0.56      0.55      0.55      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 280/400 [2:49:41<1:15:21, 37.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [280/400] Train Loss: 1.7747 Val Loss: 1.7867 Precision: 0.3350 Recall: 0.3314 F1 Score: 0.3103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.34      0.30       183\n",
      "           1       0.10      0.18      0.13       119\n",
      "           2       0.50      0.20      0.28       548\n",
      "           3       0.32      0.48      0.38       285\n",
      "           4       0.70      0.75      0.73      1801\n",
      "           5       0.13      0.03      0.04       150\n",
      "\n",
      "    accuracy                           0.55      3086\n",
      "   macro avg       0.33      0.33      0.31      3086\n",
      "weighted avg       0.55      0.55      0.53      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 320/400 [3:13:54<50:41, 38.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [320/400] Train Loss: 1.7749 Val Loss: 1.7887 Precision: 0.3475 Recall: 0.2414 F1 Score: 0.2287\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.15      0.19       183\n",
      "           1       0.09      0.15      0.11       119\n",
      "           2       0.80      0.04      0.07       548\n",
      "           3       0.27      0.20      0.23       285\n",
      "           4       0.64      0.76      0.69      1801\n",
      "           5       0.06      0.15      0.08       150\n",
      "\n",
      "    accuracy                           0.49      3086\n",
      "   macro avg       0.35      0.24      0.23      3086\n",
      "weighted avg       0.56      0.49      0.46      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 360/400 [3:38:06<25:18, 37.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [360/400] Train Loss: 1.7750 Val Loss: 1.7865 Precision: 0.3893 Recall: 0.3004 F1 Score: 0.2549\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.21      0.25       183\n",
      "           1       0.14      0.10      0.12       119\n",
      "           2       0.77      0.10      0.18       548\n",
      "           3       0.15      0.79      0.25       285\n",
      "           4       0.74      0.50      0.60      1801\n",
      "           5       0.21      0.10      0.14       150\n",
      "\n",
      "    accuracy                           0.40      3086\n",
      "   macro avg       0.39      0.30      0.25      3086\n",
      "weighted avg       0.62      0.40      0.43      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [4:02:20<00:00, 36.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/400] Train Loss: 1.7750 Val Loss: 1.7877 Precision: 0.3828 Recall: 0.2943 F1 Score: 0.2861\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.22      0.27       183\n",
      "           1       0.08      0.24      0.12       119\n",
      "           2       0.75      0.13      0.22       548\n",
      "           3       0.23      0.32      0.27       285\n",
      "           4       0.67      0.77      0.72      1801\n",
      "           5       0.21      0.08      0.12       150\n",
      "\n",
      "    accuracy                           0.53      3086\n",
      "   macro avg       0.38      0.29      0.29      3086\n",
      "weighted avg       0.58      0.53      0.51      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_csv_path = 'train_top5.csv'\n",
    "test_csv_path = 'dev_top5.csv'\n",
    "\n",
    "method = 'maxpool'\n",
    "\n",
    "train_dataset = CustomDataset(train_csv_path, onehot_encoder, method=method)\n",
    "test_dataset = CustomDataset(test_csv_path, onehot_encoder, method=method)\n",
    "\n",
    "train_batch_size = 256\n",
    "test_batch_size = 256\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "model = CustomDeepClassifier(input_dim=train_dataset[0][0].shape[1], num_classes=6)\n",
    "tl, vl, p, r, f1 = train_validate_model(model,\n",
    "                                        train_data_loader,\n",
    "                                        test_data_loader,\n",
    "                                        num_epochs=400,\n",
    "                                        learning_rate=3e-2,\n",
    "                                        stepslr=40,\n",
    "                                        gamma=0.9)\n",
    "\n",
    "torch.save(model.state_dict(), f'best_model_{method}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/400 [18:50<2:57:31, 29.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/400] Train Loss: 1.7757 Val Loss: 1.7897 Precision: 0.3069 Recall: 0.2858 F1 Score: 0.2853\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.07      0.09       183\n",
      "           1       0.07      0.11      0.08       119\n",
      "           2       0.44      0.32      0.37       548\n",
      "           3       0.37      0.24      0.29       285\n",
      "           4       0.73      0.76      0.75      1801\n",
      "           5       0.09      0.22      0.13       150\n",
      "\n",
      "    accuracy                           0.54      3086\n",
      "   macro avg       0.31      0.29      0.29      3086\n",
      "weighted avg       0.56      0.54      0.54      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 80/400 [40:09<3:05:23, 34.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/400] Train Loss: 1.7756 Val Loss: 1.7875 Precision: 0.3623 Recall: 0.3383 F1 Score: 0.3357\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.09      0.12       183\n",
      "           1       0.22      0.07      0.10       119\n",
      "           2       0.40      0.63      0.49       548\n",
      "           3       0.44      0.34      0.39       285\n",
      "           4       0.78      0.74      0.76      1801\n",
      "           5       0.17      0.16      0.16       150\n",
      "\n",
      "    accuracy                           0.59      3086\n",
      "   macro avg       0.36      0.34      0.34      3086\n",
      "weighted avg       0.59      0.59      0.58      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 120/400 [1:01:35<2:36:17, 33.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/400] Train Loss: 1.7753 Val Loss: 1.7893 Precision: 0.3495 Recall: 0.3084 F1 Score: 0.3026\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.06      0.09       183\n",
      "           1       0.12      0.05      0.07       119\n",
      "           2       0.39      0.68      0.50       548\n",
      "           3       0.49      0.20      0.28       285\n",
      "           4       0.78      0.80      0.79      1801\n",
      "           5       0.12      0.06      0.08       150\n",
      "\n",
      "    accuracy                           0.61      3086\n",
      "   macro avg       0.35      0.31      0.30      3086\n",
      "weighted avg       0.59      0.61      0.59      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 160/400 [1:23:06<2:14:04, 33.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/400] Train Loss: 1.7744 Val Loss: 1.7862 Precision: 0.3416 Recall: 0.3314 F1 Score: 0.3214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.09      0.12       183\n",
      "           1       0.19      0.08      0.12       119\n",
      "           2       0.39      0.66      0.49       548\n",
      "           3       0.38      0.25      0.30       285\n",
      "           4       0.80      0.70      0.75      1801\n",
      "           5       0.12      0.20      0.15       150\n",
      "\n",
      "    accuracy                           0.57      3086\n",
      "   macro avg       0.34      0.33      0.32      3086\n",
      "weighted avg       0.60      0.57      0.57      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [1:44:34<1:51:42, 33.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/400] Train Loss: 1.7749 Val Loss: 1.7874 Precision: 0.3363 Recall: 0.3370 F1 Score: 0.3291\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.07      0.10       183\n",
      "           1       0.11      0.09      0.10       119\n",
      "           2       0.42      0.60      0.50       548\n",
      "           3       0.38      0.41      0.40       285\n",
      "           4       0.78      0.75      0.76      1801\n",
      "           5       0.15      0.11      0.12       150\n",
      "\n",
      "    accuracy                           0.59      3086\n",
      "   macro avg       0.34      0.34      0.33      3086\n",
      "weighted avg       0.59      0.59      0.59      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 240/400 [2:06:03<1:29:21, 33.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [240/400] Train Loss: 1.7745 Val Loss: 1.7869 Precision: 0.3430 Recall: 0.3365 F1 Score: 0.3270\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.17      0.16       183\n",
      "           1       0.17      0.13      0.15       119\n",
      "           2       0.39      0.59      0.47       548\n",
      "           3       0.43      0.22      0.29       285\n",
      "           4       0.80      0.68      0.73      1801\n",
      "           5       0.13      0.22      0.16       150\n",
      "\n",
      "    accuracy                           0.55      3086\n",
      "   macro avg       0.34      0.34      0.33      3086\n",
      "weighted avg       0.60      0.55      0.56      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 280/400 [2:27:56<1:08:40, 34.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [280/400] Train Loss: 1.7742 Val Loss: 1.7865 Precision: 0.3433 Recall: 0.3449 F1 Score: 0.3222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.15      0.14       183\n",
      "           1       0.18      0.09      0.12       119\n",
      "           2       0.44      0.52      0.48       548\n",
      "           3       0.39      0.30      0.34       285\n",
      "           4       0.82      0.61      0.70      1801\n",
      "           5       0.10      0.40      0.15       150\n",
      "\n",
      "    accuracy                           0.51      3086\n",
      "   macro avg       0.34      0.34      0.32      3086\n",
      "weighted avg       0.61      0.51      0.54      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 320/400 [2:48:44<41:08, 30.85s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [320/400] Train Loss: 1.7746 Val Loss: 1.7865 Precision: 0.3424 Recall: 0.3560 F1 Score: 0.3375\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.15      0.16       183\n",
      "           1       0.16      0.12      0.14       119\n",
      "           2       0.45      0.54      0.49       548\n",
      "           3       0.37      0.40      0.39       285\n",
      "           4       0.81      0.63      0.71      1801\n",
      "           5       0.10      0.29      0.14       150\n",
      "\n",
      "    accuracy                           0.53      3086\n",
      "   macro avg       0.34      0.36      0.34      3086\n",
      "weighted avg       0.61      0.53      0.56      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 360/400 [3:07:56<20:22, 30.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [360/400] Train Loss: 1.7741 Val Loss: 1.7852 Precision: 0.3530 Recall: 0.3774 F1 Score: 0.3600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.20      0.20       183\n",
      "           1       0.15      0.20      0.17       119\n",
      "           2       0.43      0.54      0.48       548\n",
      "           3       0.35      0.37      0.36       285\n",
      "           4       0.82      0.68      0.74      1801\n",
      "           5       0.15      0.27      0.20       150\n",
      "\n",
      "    accuracy                           0.56      3086\n",
      "   macro avg       0.35      0.38      0.36      3086\n",
      "weighted avg       0.61      0.56      0.58      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [3:27:16<00:00, 31.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/400] Train Loss: 1.7740 Val Loss: 1.7867 Precision: 0.3586 Recall: 0.3675 F1 Score: 0.3605\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.20      0.20       183\n",
      "           1       0.18      0.16      0.17       119\n",
      "           2       0.49      0.53      0.51       548\n",
      "           3       0.36      0.35      0.36       285\n",
      "           4       0.80      0.73      0.76      1801\n",
      "           5       0.13      0.23      0.17       150\n",
      "\n",
      "    accuracy                           0.58      3086\n",
      "   macro avg       0.36      0.37      0.36      3086\n",
      "weighted avg       0.61      0.58      0.60      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_csv_path = 'train_top5.csv'\n",
    "test_csv_path = 'dev_top5.csv'\n",
    "\n",
    "method = 'avgpool'\n",
    "\n",
    "train_dataset = CustomDataset(train_csv_path, onehot_encoder, method=method)\n",
    "test_dataset = CustomDataset(test_csv_path, onehot_encoder, method=method)\n",
    "\n",
    "train_batch_size = 256\n",
    "test_batch_size = 256\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "model = CustomDeepClassifier(input_dim=train_dataset[0][0].shape[1], num_classes=6)\n",
    "tl, vl, p, r, f1 = train_validate_model(model,\n",
    "                                        train_data_loader,\n",
    "                                        test_data_loader,\n",
    "                                        num_epochs=400,\n",
    "                                        learning_rate=3e-2,\n",
    "                                        stepslr=40,\n",
    "                                        gamma=0.9)\n",
    "\n",
    "torch.save(model.state_dict(), f'best_model_{method}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Attention pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "data = pd.read_csv('train_top5.csv')['class'].values.reshape(-1, 1)\n",
    "onehot_encoder.fit(data)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, onehot_encoder, method='endpoint', padding_size=256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.labels = onehot_encoder.transform(self.data['class'].values.reshape(-1, 1))\n",
    "        self.method = method\n",
    "        self.padding_size = padding_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        file_path = self.data.iloc[idx]['path']\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        raw_embedding = torch.load(file_path)\n",
    "        if self.method == 'endpoint':\n",
    "            embedding = torch.cat((raw_embedding[:, 0, :], raw_embedding[:, -1, :]), dim=1)\n",
    "        elif self.method == 'diff-sum':\n",
    "            embedding = torch.cat(\n",
    "                (\n",
    "                    raw_embedding[:, 0, :] + raw_embedding[:, -1, :],\n",
    "                    raw_embedding[:, 0, :] - raw_embedding[:, -1, :]\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        elif self.method == 'coherent':\n",
    "            embedding = torch.cat(\n",
    "                (\n",
    "                    raw_embedding[:, 0, :360],\n",
    "                    raw_embedding[:, -1, 360:720],\n",
    "                    torch.dot(\n",
    "                        raw_embedding[:, 0, :].squeeze()[720:],\n",
    "                        raw_embedding[:, -1, :].squeeze()[720:]\n",
    "                    ).unsqueeze(0).unsqueeze(0)\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        elif self.method == 'maxpool':\n",
    "            embedding = torch.max(raw_embedding, dim=1)[0]\n",
    "        elif self.method == 'avgpool':\n",
    "            embedding = torch.mean(raw_embedding, dim=1)\n",
    "        else:\n",
    "            embedding = raw_embedding\n",
    "            padding = torch.zeros(1, self.padding_size - embedding.shape[1], embedding.shape[-1])\n",
    "            embedding = torch.cat((embedding, padding), dim=1)\n",
    "\n",
    "        return embedding, torch.tensor(label)\n",
    "\n",
    "\n",
    "class CustomAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=1024, proj_dim=256, num_layers=3, num_classes=20):\n",
    "        super(CustomAttention, self).__init__()\n",
    "\n",
    "        self.projection = nn.Linear(input_dim, proj_dim)\n",
    "\n",
    "        self.attention_params = nn.Linear(proj_dim, 1)\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(proj_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.BatchNorm1d(1))\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(1))\n",
    "        layers.append(nn.Linear(hidden_dim, num_classes))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        embeddings = self.projection(embeddings)\n",
    "\n",
    "        attn_logits = self.attention_params(embeddings)\n",
    "        attention_wts = nn.functional.softmax(attn_logits, dim=2)\n",
    "\n",
    "        attention_term = torch.sum(attention_wts * embeddings, dim=-1)\n",
    "\n",
    "        output = self.layers(attention_term)\n",
    "        \n",
    "        output = F.softmax(output, dim=0)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "\n",
    "def train_validate_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.1, stepslr=10, step_report=10, gamma=0.9):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([1./183, 1./119, 1./548, 1./285, 1./1801, 1./150]).to(device))\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, stepslr, gamma=gamma)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), total=num_epochs, leave=False):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.float())\n",
    "            # print(outputs.device, labels.device)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "        \n",
    "        train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs.float())\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                predicted = torch.argmax(outputs.squeeze(1), 1)\n",
    "                labels = torch.argmax(labels, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] \"\n",
    "            f\"Train Loss: {train_loss:.4f} \"\n",
    "            f\"Val Loss: {val_loss:.4f} \"\n",
    "            f\"Precision: {precision:.4f} \"\n",
    "            f\"Recall: {recall:.4f} \"\n",
    "            f\"F1 Score: {f1:.4f}\")\n",
    "        if (epoch + 1) % step_report == 0:\n",
    "            print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    return train_losses, val_losses, precision_scores, recall_scores, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:56<1:33:50, 56.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.1999 Recall: 0.2095 F1 Score: 0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [01:53<1:32:35, 56.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2141 Recall: 0.1857 F1 Score: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [02:48<1:30:18, 55.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2515 Recall: 0.1914 F1 Score: 0.1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [03:43<1:28:51, 55.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2527 Recall: 0.2078 F1 Score: 0.0695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [04:37<1:27:05, 55.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2428 Recall: 0.2080 F1 Score: 0.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [05:32<1:26:14, 55.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2371 Recall: 0.2140 F1 Score: 0.1064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [06:28<1:25:37, 55.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2703 Recall: 0.2108 F1 Score: 0.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [07:24<1:25:05, 55.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2833 Recall: 0.2158 F1 Score: 0.0960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [08:19<1:24:06, 55.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2483 Recall: 0.2132 F1 Score: 0.0974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [09:14<1:22:47, 55.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2302 Recall: 0.2066 F1 Score: 0.1008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.01      0.01       183\n",
      "           1       0.04      0.23      0.06       119\n",
      "           2       0.29      0.20      0.23       548\n",
      "           3       0.11      0.72      0.19       285\n",
      "           4       0.77      0.01      0.01      1801\n",
      "           5       0.11      0.08      0.09       150\n",
      "\n",
      "    accuracy                           0.12      3086\n",
      "   macro avg       0.23      0.21      0.10      3086\n",
      "weighted avg       0.52      0.12      0.07      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [10:11<1:22:53, 55.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2313 Recall: 0.2110 F1 Score: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [11:05<1:21:10, 55.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2231 Recall: 0.1977 F1 Score: 0.1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [12:01<1:20:35, 55.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2461 Recall: 0.2106 F1 Score: 0.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [12:55<1:18:47, 54.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2414 Recall: 0.2117 F1 Score: 0.1198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [13:52<1:18:41, 55.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2346 Recall: 0.2033 F1 Score: 0.1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [14:55<1:21:08, 57.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2251 Recall: 0.2027 F1 Score: 0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [15:50<1:18:55, 57.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2329 Recall: 0.1959 F1 Score: 0.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [16:45<1:16:59, 56.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2376 Recall: 0.1958 F1 Score: 0.1083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [17:42<1:16:29, 56.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2420 Recall: 0.2097 F1 Score: 0.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [18:38<1:15:01, 56.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2078 Recall: 0.2106 F1 Score: 0.1112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       183\n",
      "           1       0.06      0.16      0.09       119\n",
      "           2       0.28      0.34      0.31       548\n",
      "           3       0.10      0.68      0.17       285\n",
      "           4       0.70      0.00      0.01      1801\n",
      "           5       0.11      0.08      0.09       150\n",
      "\n",
      "    accuracy                           0.14      3086\n",
      "   macro avg       0.21      0.21      0.11      3086\n",
      "weighted avg       0.47      0.14      0.08      3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [19:32<1:13:24, 55.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2356 Recall: 0.1585 F1 Score: 0.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [20:28<1:12:31, 55.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2060 Recall: 0.2011 F1 Score: 0.1064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [21:30<1:13:55, 57.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2684 Recall: 0.2016 F1 Score: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [22:32<1:14:47, 59.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100] Train Loss: 0.0036 Val Loss: 0.0033 Precision: 0.2673 Recall: 0.1893 F1 Score: 0.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m test_data_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mtest_batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m CustomAttention(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m768\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m tl, vl, p, r, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_validate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mstepslr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 119\u001b[0m, in \u001b[0;36mtrain_validate_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, learning_rate, stepslr, step_report, gamma)\u001b[0m\n\u001b[1;32m    117\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    118\u001b[0m running_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/test/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/test/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/test/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/test/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     33\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m---> 35\u001b[0m raw_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendpoint\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     37\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((raw_embedding[:, \u001b[38;5;241m0\u001b[39m, :], raw_embedding[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/test/.venv/lib/python3.11/site-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/test/.venv/lib/python3.11/site-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
      "File \u001b[0;32m~/test/.venv/lib/python3.11/site-packages/torch/serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1391\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1392\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/test/.venv/lib/python3.11/site-packages/torch/serialization.py:1357\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1357\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_csv_path = 'train_top5.csv'\n",
    "test_csv_path = 'dev_top5.csv'\n",
    "\n",
    "method = 'attnpool'\n",
    "\n",
    "train_dataset = CustomDataset(train_csv_path, onehot_encoder, method=method)\n",
    "test_dataset = CustomDataset(test_csv_path, onehot_encoder, method=method)\n",
    "\n",
    "train_batch_size = 256\n",
    "test_batch_size = 256\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "model = CustomAttention(input_dim=768, num_classes=6).to(device)\n",
    "tl, vl, p, r, f1 = train_validate_model(model,\n",
    "                                        train_data_loader,\n",
    "                                        test_data_loader,\n",
    "                                        num_epochs=100,\n",
    "                                        learning_rate=3e-2,\n",
    "                                        stepslr=10,\n",
    "                                        gamma=0.5)\n",
    "\n",
    "torch.save(model.state_dict(), f'best_model_{method}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
